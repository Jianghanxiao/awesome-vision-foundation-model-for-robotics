# Awesome-Vision-Foundation-Models-for-Robotics
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

This repository aims to be a concise, practical dictionary of vision foundation models (VFMs) useful for robotics research. We define VFMs broadly: models that operate on vision tasks, are pretrained on large datasets, and demonstrate strong zero-/few-shot generalization. The goal is to make it easier for robotics researchers to discover candidate models for integration into perception, planning, and control pipelines.

We collect and organize papers by task category (e.g., detection, segmentation, correspondence, tracking, reconstruction, generation). Each entry will include a short description, key capabilities, and notes on robotic applicability (strengths, limitations, and potential use cases).

Contributions welcome â€” please open an issue or submit a pull request with new papers, corrections, or suggestions.
